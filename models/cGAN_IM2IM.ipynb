{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from dataloader import dataset\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_BN_ReLU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super(Conv_BN_ReLU, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1, stride=1)\n",
    "        self.norm = nn.BatchNorm3d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeConv_BN_ReLU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super(DeConv_BN_ReLU, self).__init__()\n",
    "        self.deconv = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn = nn.BatchNorm3d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.deconv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet3D, self).__init__()\n",
    "        #\n",
    "        #self.encoder1 = Conv_BN_ReLU(in_channels, 64)\n",
    "        self.conv1 = nn.Conv3d(in_channels,64, kernel_size=3, padding=1, stride=1)\n",
    "        self.norm1 = nn.BatchNorm3d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        #\n",
    "        #self.encoder2 = Conv_BN_ReLU(64, 128)\n",
    "        self.conv2 = nn.Conv3d(64,128, kernel_size=3, padding=1, stride=1)\n",
    "        self.norm2 = nn.BatchNorm3d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        #\n",
    "        #self.encoder3_1 = Conv_BN_ReLU(128, 256)\n",
    "        self.conv3_1 = nn.Conv3d(128,256, kernel_size=3, padding=1, stride=1)\n",
    "        self.norm3_1 = nn.BatchNorm3d(256)\n",
    "        self.relu3_1 = nn.ReLU()\n",
    "        #self.encoder3_2 = Conv_BN_ReLU(256, 256)\n",
    "        self.conv3_2 = nn.Conv3d(256,256, kernel_size=3, padding=1, stride=1)\n",
    "        self.norm3_2 = nn.BatchNorm3d(256)\n",
    "        self.relu3_2 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        #\n",
    "        #self.encoder4_1 = Conv_BN_ReLU(256, 512)\n",
    "        self.conv4_1 = nn.Conv3d(256,512, kernel_size=3, padding=1, stride=1)\n",
    "        self.norm4_1 = nn.BatchNorm3d(512)\n",
    "        self.relu4_1 = nn.ReLU()\n",
    "        self.encoder4_2 = Conv_BN_ReLU(512, 512)\n",
    "        self.conv4_2 = nn.Conv3d(512,512, kernel_size=3, padding=1, stride=1)\n",
    "        self.norm4_2 = nn.BatchNorm3d(512)\n",
    "        self.relu4_2 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        #\n",
    "        self.bottleneck1 = Conv_BN_ReLU(512,512)\n",
    "        self.bottleneck2 = Conv_BN_ReLU(512,512) \n",
    "        #\n",
    "        self.decoder1_1 = DeConv_BN_ReLU(512,512) \n",
    "        self.decoder1_2 = Conv_BN_ReLU(1024,256)\n",
    "        #\n",
    "        self.decoder2_1 = DeConv_BN_ReLU(256,256)\n",
    "        self.decoder2_2 = Conv_BN_ReLU(512,128)\n",
    "        #\n",
    "        self.decoder3_1 = DeConv_BN_ReLU(128,128)\n",
    "        self.decoder3_2 = Conv_BN_ReLU(256,64)\n",
    "        #\n",
    "        self.decoder4_1 = DeConv_BN_ReLU(64,64)\n",
    "        self.decoder4_2 = Conv_BN_ReLU(128,32)\n",
    "        #\n",
    "        self.final_conv = nn.Conv3d(32, out_channels, kernel_size=1, stride=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #enc1 = self.encoder1(x)\n",
    "        conv1 = self.conv1(x)\n",
    "        norm1 = self.norm1(conv1)\n",
    "        relu1 = self.relu1(norm1)\n",
    "        pool1 = self.pool1(relu1)\n",
    "        #\n",
    "        #enc2 = self.encoder2(self.pool1(enc1))\n",
    "        conv2 = self.conv2(pool1)\n",
    "        norm2 = self.norm2(conv2)\n",
    "        relu2 = self.relu2(norm2)\n",
    "        pool2 = self.pool2(relu2)\n",
    "        #\n",
    "        #enc3_1 = self.encoder3_1(self.pool2(enc2))\n",
    "        conv3_1 = self.conv3_1(pool2)\n",
    "        norm3_1 = self.norm3_1(conv3_1)\n",
    "        relu3_1 = self.relu3_1(norm3_1)\n",
    "        #enc3_2 = self.encoder3_2(enc3_1)\n",
    "        conv3_2 = self.conv3_2(relu3_1)\n",
    "        norm3_2 = self.norm3_2(conv3_2)\n",
    "        relu3_2 = self.relu3_2(norm3_2)\n",
    "        pool3 = self.pool3(relu3_2)\n",
    "        #\n",
    "        #enc4_1 = self.encoder4_1(self.pool3(enc3_2))\n",
    "        conv4_1 = self.conv4_1(pool3)\n",
    "        norm4_1 = self.norm4_1(conv4_1)\n",
    "        relu4_1 = self.relu4_1(norm4_1)\n",
    "        #enc4_2 = self.encoder4_2(self.pool3(enc4_1))\n",
    "        conv4_2 = self.conv4_2(relu4_1)\n",
    "        norm4_2 = self.norm4_2(conv4_2)\n",
    "        relu4_2 = self.relu4_2(norm4_2)\n",
    "        pool4 = self.pool4(relu4_2) #[bs, 512, 4, 4, 4]\n",
    "\n",
    "        bottleneck1 = self.bottleneck1(pool4) #[bs, 512, 4, 4, 4]\n",
    "        bottleneck2 = self.bottleneck2(bottleneck1) #[bs, 512, 4, 4, 4]\n",
    "\n",
    "        dec1_1 = self.decoder1_1(bottleneck2) #[bs, 512, 4, 4, 4]\n",
    "        con1 = torch.cat((dec1_1,conv4_2),dim=1) #[bs, 1024, 4, 4, 4]\n",
    "        dec1_2 = self.decoder1_2(con1) #[bs, 256, 8, 8, 8]\n",
    "        \n",
    "        dec2_1 = self.decoder2_1(dec1_2) #[bs, 256, 16, 16, 16]\n",
    "        con2 = torch.cat((dec2_1,conv3_2),dim=1)\n",
    "        dec2_2 = self.decoder2_2(con2) #[bs, 128, 16, 16, 16]\n",
    "\n",
    "        dec3_1 = self.decoder3_1(dec2_2)\n",
    "        con3 = torch.cat((dec3_1,conv2),dim=1)\n",
    "        dec3_2 = self.decoder3_2(con3)\n",
    "\n",
    "        dec4_1 = self.decoder4_1(dec3_2)\n",
    "        con4 = torch.cat((dec4_1,conv1),dim=1)\n",
    "        dec4_2 = self.decoder4_2(con4) #[bs, 32, 64, 64, 64]\n",
    "\n",
    "        output = self.final_conv(dec4_2)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels, 64, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv3d(64, 128, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv3d(128, 256, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv3d(256, 512, kernel_size=4, stride=2, padding=1)\n",
    "        self.linear = nn.Linear(32768, 1)\n",
    "\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.leaky_relu(self.conv1(x))\n",
    "        x = self.leaky_relu(self.conv2(x))\n",
    "        x = self.leaky_relu(self.conv3(x))\n",
    "        x = self.leaky_relu(self.conv4(x))\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  \n",
    "        \n",
    "        x = self.linear(x)  \n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.randn((8, 2, 64, 64, 64)).to(device)\n",
    "tensor2 = torch.randn((8, 2, 64, 64, 64)).to(device)\n",
    "print(torch.concat((tensor1,tensor2),dim=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = Discriminator(in_channels=2).to(device)\n",
    "input_tensor = torch.randn((2, 2, 64, 64, 64)).to(device)\n",
    "out = dis(input_tensor)\n",
    "out.shape\n",
    "summary(dis, input_size=(2, 64, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cGAN_IM2IM(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super(cGAN_IM2IM, self).__init__()\n",
    "        self.in_channel = in_channels\n",
    "        self.out_channel = out_channels\n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "\n",
    "    def build_generator(self):\n",
    "        return UNet3D(self.in_channel,self.out_channel)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        return Discriminator(self.in_channel*2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        generated_images = self.generator(x)\n",
    "        discriminator_output = self.discriminator(generated_images)\n",
    "        return generated_images, discriminator_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainingset = dataset(file_path1=\"./reg_data/00/\",file_path2=\"./reg_data/12/\",force=0,start_index=144,end_index=720)\n",
    "trainingloader = DataLoader(dataset=Trainingset,batch_size=8,shuffle=True)\n",
    "\n",
    "Testingset = dataset(file_path1=\"./reg_data/00/\",file_path2=\"./reg_data/12/\",force=0,start_index=0,end_index=144)\n",
    "testloader = DataLoader(dataset=Testingset,batch_size=8,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_cgan_im2im(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    loss_total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets,_ in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs = inputs.unsqueeze(1).float()\n",
    "            targets = targets.unsqueeze(1).float()\n",
    "\n",
    "            generated_images = model.generator(inputs)\n",
    "            loss = criterion(generated_images,targets)\n",
    "            loss_total += loss.item() * inputs.size(0)\n",
    "\n",
    "        loss_total /= len(val_loader.dataset)\n",
    "    return loss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cgan_im2im(model, train_loader, val_loader, num_epochs, device, lr=0.0002, beta1=0.5, beta2=0.999):\n",
    "    \n",
    "    optimizer_gen = optim.Adam(model.generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "    optimizer_disc = optim.Adam(model.discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "    criterion_BCE = nn.BCELoss()\n",
    "    #criterion = nn.L1Loss()\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    model.to(device)\n",
    "    gen_losses = []\n",
    "    sim_losses = []\n",
    "    dis_losses = []\n",
    "    val_losses = []\n",
    "    min_val = 1.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        gen_loss_total = 0.0\n",
    "        sim_loss_total = 0.0\n",
    "        disc_loss_total = 0.0\n",
    "        model.train()\n",
    "        for inputs, targets,_ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs = inputs.unsqueeze(1).float()\n",
    "            targets = targets.unsqueeze(1).float()\n",
    "\n",
    "            optimizer_disc.zero_grad()\n",
    "\n",
    "            real_labels = torch.ones(inputs.size(0), 1).to(device)\n",
    "            fake_labels = torch.zeros(inputs.size(0), 1).to(device)\n",
    "\n",
    "            generated_images = model.generator(inputs)\n",
    "            real_outputs = model.discriminator(torch.concat((inputs,targets),dim=1))\n",
    "            fake_outputs = model.discriminator(torch.concat((inputs,generated_images.detach()),dim=1))\n",
    "\n",
    "            disc_loss_real = criterion_BCE(real_outputs, real_labels)\n",
    "            disc_loss_fake = criterion_BCE(fake_outputs, fake_labels)\n",
    "            disc_loss = disc_loss_real + disc_loss_fake\n",
    "\n",
    "            # if disc_loss.item() > 0.01:\n",
    "            disc_loss.backward()\n",
    "            optimizer_disc.step()\n",
    "\n",
    "\n",
    "            optimizer_gen.zero_grad()\n",
    "\n",
    "            generated_images = model.generator(inputs)\n",
    "            fake_outputs = model.discriminator(torch.concat((inputs,generated_images.detach()),dim=1))\n",
    "\n",
    "            gen_loss1 = criterion_BCE(fake_outputs, real_labels)\n",
    "            gen_loss2 = criterion(generated_images,targets)\n",
    "            gen_loss = gen_loss1 + 100*gen_loss2\n",
    "            # if gen_loss.item() > 0.01:\n",
    "            gen_loss.backward()\n",
    "            optimizer_gen.step()\n",
    "\n",
    "            gen_loss_total += gen_loss1.item() * inputs.size(0)\n",
    "            sim_loss_total += gen_loss2.item() * inputs.size(0)\n",
    "            disc_loss_total += disc_loss.item() * inputs.size(0)\n",
    "\n",
    "        gen_loss_total /= len(train_loader.dataset)\n",
    "        gen_losses.append(gen_loss_total)\n",
    "        sim_loss_total /= len(train_loader.dataset)\n",
    "        sim_losses.append(sim_loss_total)\n",
    "        disc_loss_total /= len(train_loader.dataset)\n",
    "        dis_losses.append(disc_loss_total)\n",
    "\n",
    "\n",
    "        val_loss = eval_cgan_im2im(model,val_loader,criterion)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if val_loss < min_val:\n",
    "            min_val = val_loss\n",
    "            if val_loss < 0.05:\n",
    "                torch.save(model.state_dict(), f'./saved_model/cGAN/{epoch}_{val_loss:.4f}_lr1e-6.pth')\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Generator Loss: {gen_loss_total:.4f}, Similarity Loss: {sim_loss_total:.4f}, Discriminator Loss: {disc_loss_total:.4f},val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    return gen_losses, sim_losses, dis_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_model = cGAN_IM2IM(1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_loss, sim_loss, dis_loss, val_loss = train_cgan_im2im(gan_model, trainingloader, testloader, 400, device, lr=0.000001, beta1=0.5, beta2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mt_xiangyu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
