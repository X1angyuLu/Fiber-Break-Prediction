{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from dataloader import dataset\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_BN_ReLU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super(Conv_BN_ReLU, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1, stride=1)\n",
    "        self.norm = nn.BatchNorm3d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeConv_BN_ReLU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super(DeConv_BN_ReLU, self).__init__()\n",
    "        self.deconv = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn = nn.BatchNorm3d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.deconv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet3D, self).__init__()\n",
    "        #\n",
    "        #self.encoder1 = Conv_BN_ReLU(in_channels, 64)\n",
    "        self.conv1 = nn.Conv3d(in_channels,64, kernel_size=3, padding=1, stride=1)\n",
    "        self.norm1 = nn.BatchNorm3d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        #\n",
    "        #self.encoder2 = Conv_BN_ReLU(64, 128)\n",
    "        self.conv2 = nn.Conv3d(64,128, kernel_size=3, padding=1, stride=1)\n",
    "        self.norm2 = nn.BatchNorm3d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        #\n",
    "        #self.encoder3_1 = Conv_BN_ReLU(128, 256)\n",
    "        self.conv3_1 = nn.Conv3d(128,256, kernel_size=3, padding=1, stride=1)\n",
    "        self.norm3_1 = nn.BatchNorm3d(256)\n",
    "        self.relu3_1 = nn.ReLU()\n",
    "        #self.encoder3_2 = Conv_BN_ReLU(256, 256)\n",
    "        self.conv3_2 = nn.Conv3d(256,256, kernel_size=3, padding=1, stride=1)\n",
    "        self.norm3_2 = nn.BatchNorm3d(256)\n",
    "        self.relu3_2 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        #\n",
    "        #self.encoder4_1 = Conv_BN_ReLU(256, 512)\n",
    "        self.conv4_1 = nn.Conv3d(256,512, kernel_size=3, padding=1, stride=1)\n",
    "        self.norm4_1 = nn.BatchNorm3d(512)\n",
    "        self.relu4_1 = nn.ReLU()\n",
    "        self.encoder4_2 = Conv_BN_ReLU(512, 512)\n",
    "        self.conv4_2 = nn.Conv3d(512,512, kernel_size=3, padding=1, stride=1)\n",
    "        self.norm4_2 = nn.BatchNorm3d(512)\n",
    "        self.relu4_2 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        #\n",
    "        self.bottleneck1 = Conv_BN_ReLU(512,512)\n",
    "        self.bottleneck2 = Conv_BN_ReLU(512,512) \n",
    "        #\n",
    "        self.decoder1_1 = DeConv_BN_ReLU(512,512) \n",
    "        self.decoder1_2 = Conv_BN_ReLU(1024,256)\n",
    "        #\n",
    "        self.decoder2_1 = DeConv_BN_ReLU(256,256)\n",
    "        self.decoder2_2 = Conv_BN_ReLU(512,128)\n",
    "        #\n",
    "        self.decoder3_1 = DeConv_BN_ReLU(128,128)\n",
    "        self.decoder3_2 = Conv_BN_ReLU(256,64)\n",
    "        #\n",
    "        self.decoder4_1 = DeConv_BN_ReLU(64,64)\n",
    "        self.decoder4_2 = Conv_BN_ReLU(128,32)\n",
    "        #\n",
    "        self.final_conv = nn.Conv3d(32, out_channels, kernel_size=1, stride=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #enc1 = self.encoder1(x)\n",
    "        conv1 = self.conv1(x)\n",
    "        norm1 = self.norm1(conv1)\n",
    "        relu1 = self.relu1(norm1)\n",
    "        pool1 = self.pool1(relu1)\n",
    "        #\n",
    "        #enc2 = self.encoder2(self.pool1(enc1))\n",
    "        conv2 = self.conv2(pool1)\n",
    "        norm2 = self.norm2(conv2)\n",
    "        relu2 = self.relu2(norm2)\n",
    "        pool2 = self.pool2(relu2)\n",
    "        #\n",
    "        #enc3_1 = self.encoder3_1(self.pool2(enc2))\n",
    "        conv3_1 = self.conv3_1(pool2)\n",
    "        norm3_1 = self.norm3_1(conv3_1)\n",
    "        relu3_1 = self.relu3_1(norm3_1)\n",
    "        #enc3_2 = self.encoder3_2(enc3_1)\n",
    "        conv3_2 = self.conv3_2(relu3_1)\n",
    "        norm3_2 = self.norm3_2(conv3_2)\n",
    "        relu3_2 = self.relu3_2(norm3_2)\n",
    "        pool3 = self.pool3(relu3_2)\n",
    "        #\n",
    "        #enc4_1 = self.encoder4_1(self.pool3(enc3_2))\n",
    "        conv4_1 = self.conv4_1(pool3)\n",
    "        norm4_1 = self.norm4_1(conv4_1)\n",
    "        relu4_1 = self.relu4_1(norm4_1)\n",
    "        #enc4_2 = self.encoder4_2(self.pool3(enc4_1))\n",
    "        conv4_2 = self.conv4_2(relu4_1)\n",
    "        norm4_2 = self.norm4_2(conv4_2)\n",
    "        relu4_2 = self.relu4_2(norm4_2)\n",
    "        pool4 = self.pool4(relu4_2) #[bs, 512, 4, 4, 4]\n",
    "\n",
    "        bottleneck1 = self.bottleneck1(pool4) #[bs, 512, 4, 4, 4]\n",
    "        bottleneck2 = self.bottleneck2(bottleneck1) #[bs, 512, 4, 4, 4]\n",
    "\n",
    "        dec1_1 = self.decoder1_1(bottleneck2) #[bs, 512, 4, 4, 4]\n",
    "        con1 = torch.cat((dec1_1,conv4_2),dim=1) #[bs, 1024, 4, 4, 4]\n",
    "        dec1_2 = self.decoder1_2(con1) #[bs, 256, 8, 8, 8]\n",
    "        \n",
    "        dec2_1 = self.decoder2_1(dec1_2) #[bs, 256, 16, 16, 16]\n",
    "        con2 = torch.cat((dec2_1,conv3_2),dim=1)\n",
    "        dec2_2 = self.decoder2_2(con2) #[bs, 128, 16, 16, 16]\n",
    "\n",
    "        dec3_1 = self.decoder3_1(dec2_2)\n",
    "        con3 = torch.cat((dec3_1,conv2),dim=1)\n",
    "        dec3_2 = self.decoder3_2(con3)\n",
    "\n",
    "        dec4_1 = self.decoder4_1(dec3_2)\n",
    "        con4 = torch.cat((dec4_1,conv1),dim=1)\n",
    "        dec4_2 = self.decoder4_2(con4) #[bs, 32, 64, 64, 64]\n",
    "\n",
    "        output = self.final_conv(dec4_2)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = Conv_BN_ReLU(in_channels,32)\n",
    "        self.conv2 = Conv_BN_ReLU(32,64)\n",
    "        self.conv3 = Conv_BN_ReLU(64,64)\n",
    "        self.conv4 = Conv_BN_ReLU(64,64)\n",
    "        self.linear = nn.Linear(16777216, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        \n",
    "        x = self.linear(x)  \n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainingset = dataset(file_path1=\"./reg_data/00/\",file_path2=\"./reg_data/12/\",force=0)\n",
    "trainingloader = DataLoader(dataset=Trainingset,batch_size=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG_0_12 = UNet3D(1,1).to(device)\n",
    "netG_12_0 = UNet3D(1,1).to(device)\n",
    "netD_0 = Discriminator(1).to(device)\n",
    "netD_12 = Discriminator(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_GAN = nn.BCELoss()\n",
    "criterion_cycle = nn.L1Loss()\n",
    "\n",
    "optimizer_G = optim.Adam(\n",
    "    itertools.chain(netG_0_12.parameters(), netG_12_0.parameters()), lr=0.000001, betas=(0.5, 0.999)\n",
    ")\n",
    "optimizer_D_A = optim.Adam(netD_0.parameters(), lr=0.0000001, betas=(0.5, 0.999))\n",
    "optimizer_D_B = optim.Adam(netD_12.parameters(), lr=0.0000001, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    gen_loss_total = 0.0\n",
    "    disc0_loss_total = 0.0\n",
    "    disc12_loss_total = 0.0\n",
    "    for inputs, targets, force in tqdm(trainingloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "\n",
    "        real_A = inputs.to(device).unsqueeze(1).float()\n",
    "        real_B = targets.to(device).unsqueeze(1).float()\n",
    "\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "\n",
    "        fake_B = netG_0_12(real_A)\n",
    "        recov_A = netG_12_0(fake_B)\n",
    "\n",
    " \n",
    "        fake_A = netG_12_0(real_B)\n",
    "        recov_B = netG_0_12(fake_A)\n",
    "\n",
    "   \n",
    "        pred_fake_A = netD_0(fake_A)\n",
    "        loss_GAN_A2B = criterion_GAN(pred_fake_A, torch.ones_like(pred_fake_A))\n",
    "        pred_fake_B = netD_12(fake_B)\n",
    "        loss_GAN_B2A = criterion_GAN(pred_fake_B, torch.ones_like(pred_fake_B))\n",
    "\n",
    "        # Cycle consistency loss\n",
    "        loss_cycle_A = criterion_cycle(recov_A, real_A)\n",
    "        loss_cycle_B = criterion_cycle(recov_B, real_B)\n",
    "\n",
    "        \n",
    "        loss_G = loss_GAN_A2B + loss_GAN_B2A + loss_cycle_A + loss_cycle_B\n",
    "\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        \n",
    "        optimizer_D_A.zero_grad()\n",
    "        pred_real_A = netD_0(real_A)\n",
    "        loss_D_real_A = criterion_GAN(pred_real_A, torch.ones_like(pred_real_A))\n",
    "        pred_fake_A = netD_0(fake_A.detach())\n",
    "        loss_D_fake_A = criterion_GAN(pred_fake_A, torch.zeros_like(pred_fake_A))\n",
    "        loss_D_A = 0.5 * (loss_D_real_A + loss_D_fake_A)\n",
    "        loss_D_A.backward()\n",
    "        optimizer_D_A.step()\n",
    "\n",
    "        \n",
    "        optimizer_D_B.zero_grad()\n",
    "        pred_real_B = netD_12(real_B)\n",
    "        loss_D_real_B = criterion_GAN(pred_real_B, torch.ones_like(pred_real_B))\n",
    "        pred_fake_B = netD_12(fake_B.detach())\n",
    "        loss_D_fake_B = criterion_GAN(pred_fake_B, torch.zeros_like(pred_fake_B))\n",
    "        loss_D_B = 0.5 * (loss_D_real_B + loss_D_fake_B)\n",
    "        loss_D_B.backward()\n",
    "        optimizer_D_B.step()\n",
    "\n",
    "        gen_loss_total += loss_G.item() * inputs.size(0)\n",
    "        disc0_loss_total += loss_D_A.item() * inputs.size(0)\n",
    "        disc12_loss_total += loss_D_B.item() * inputs.size(0)\n",
    "\n",
    "    gen_loss_total /= len(trainingloader.dataset)\n",
    "    disc0_loss_total /= len(trainingloader.dataset)\n",
    "    disc12_loss_total /= len(trainingloader.dataset)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Generator Loss: {gen_loss_total:.4f}, DiscriminatorA Loss: {disc0_loss_total:.4f}, DiscriminatorB Loss: {disc12_loss_total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DenseNet import *\n",
    "densenet = DenseNet3D()\n",
    "\n",
    "densenet.load_state_dict(torch.load('./saved_model/DenseNet/model400.pth'))\n",
    "densenet = densenet.to(device)\n",
    "\n",
    "for param in densenet.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG_0_12 = UNet3D(1,1).to(device)\n",
    "netG_12_0 = UNet3D(1,1).to(device)\n",
    "netD_0 = Discriminator(1).to(device)\n",
    "netD_12 = Discriminator(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG_0_12.load_state_dict(torch.load('./saved_model/cycleGAN/netG_0_12.pth'))\n",
    "netG_12_0.load_state_dict(torch.load( './saved_model/cycleGAN/netG_12_0.pth'))\n",
    "netD_0.load_state_dict(torch.load('./saved_model/cycleGAN/netD_0.pth'))\n",
    "netD_12.load_state_dict(torch.load('./saved_model/cycleGAN/netD_12.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainingset = dataset(file_path1=\"./reg_data/00/\",file_path2=\"./reg_data/12/\",force=0,end_index=576)\n",
    "trainingloader = DataLoader(dataset=Trainingset,batch_size=4,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_GAN = nn.BCELoss()\n",
    "criterion_cycle = nn.L1Loss()\n",
    "criterion_MSE = nn.MSELoss()\n",
    "\n",
    "optimizer_G = optim.Adam(\n",
    "    itertools.chain(netG_0_12.parameters(), netG_12_0.parameters()), lr=0.000001, betas=(0.5, 0.999)\n",
    ")\n",
    "optimizer_D_A = optim.Adam(netD_0.parameters(), lr=0.0000001, betas=(0.5, 0.999))\n",
    "optimizer_D_B = optim.Adam(netD_12.parameters(), lr=0.0000001, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    gen_loss_total = 0.0\n",
    "    disc0_loss_total = 0.0\n",
    "    disc12_loss_total = 0.0\n",
    "    for inputs, targets, force in tqdm(trainingloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "\n",
    "        real_A = inputs.to(device).unsqueeze(1).float()\n",
    "        real_B = targets.to(device).unsqueeze(1).float()\n",
    "\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "\n",
    "        fake_B = netG_0_12(real_A)\n",
    "        recov_A = netG_12_0(fake_B)\n",
    "\n",
    " \n",
    "        fake_A = netG_12_0(real_B)\n",
    "        recov_B = netG_0_12(fake_A)\n",
    "\n",
    "   \n",
    "        pred_fake_A = netD_0(fake_A)\n",
    "        loss_GAN_A2B = criterion_GAN(pred_fake_A, torch.ones_like(pred_fake_A))\n",
    "        pred_fake_B = netD_12(fake_B)\n",
    "        loss_GAN_B2A = criterion_GAN(pred_fake_B, torch.ones_like(pred_fake_B))\n",
    "\n",
    "        # Cycle consistency loss\n",
    "        loss_cycle_A = criterion_cycle(recov_A, real_A)\n",
    "        loss_cycle_B = criterion_cycle(recov_B, real_B)\n",
    "\n",
    "        # feature loss\n",
    "        loss_fea_A = criterion_cycle(fake_A,real_A)\n",
    "        loss_fea_B = criterion_cycle(fake_B,real_B)\n",
    "\n",
    "        \n",
    "        loss_G = loss_GAN_A2B + loss_GAN_B2A + loss_cycle_A + loss_cycle_B + 25*loss_fea_A + 25*loss_fea_B\n",
    "\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        \n",
    "        optimizer_D_A.zero_grad()\n",
    "        pred_real_A = netD_0(real_A)\n",
    "        loss_D_real_A = criterion_GAN(pred_real_A, torch.ones_like(pred_real_A))\n",
    "        pred_fake_A = netD_0(fake_A.detach())\n",
    "        loss_D_fake_A = criterion_GAN(pred_fake_A, torch.zeros_like(pred_fake_A))\n",
    "        loss_D_A = 0.5 * (loss_D_real_A + loss_D_fake_A)\n",
    "        # if loss_D_A.item()>0.01:\n",
    "        loss_D_A.backward()\n",
    "        optimizer_D_A.step()\n",
    "\n",
    "        \n",
    "        optimizer_D_B.zero_grad()\n",
    "        pred_real_B = netD_12(real_B)\n",
    "        loss_D_real_B = criterion_GAN(pred_real_B, torch.ones_like(pred_real_B))\n",
    "        pred_fake_B = netD_12(fake_B.detach())\n",
    "        loss_D_fake_B = criterion_GAN(pred_fake_B, torch.zeros_like(pred_fake_B))\n",
    "        loss_D_B = 0.5 * (loss_D_real_B + loss_D_fake_B)\n",
    "        # if loss_D_B.item()>0.01:\n",
    "        loss_D_B.backward()\n",
    "        optimizer_D_B.step()\n",
    "\n",
    "        gen_loss_total += loss_G.item() * inputs.size(0)\n",
    "        disc0_loss_total += loss_D_A.item() * inputs.size(0)\n",
    "        disc12_loss_total += loss_D_B.item() * inputs.size(0)\n",
    "\n",
    "\n",
    "    gen_loss_total /= len(trainingloader.dataset)\n",
    "    disc0_loss_total /= len(trainingloader.dataset)\n",
    "    disc12_loss_total /= len(trainingloader.dataset)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Generator Loss: {gen_loss_total:.4f}, DiscriminatorA Loss: {disc0_loss_total:.4f}, DiscriminatorB Loss: {disc12_loss_total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mt_xiangyu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
