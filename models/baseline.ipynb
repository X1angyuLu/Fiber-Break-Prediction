{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from dataloader import dataset\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3dunet.unet3d import *\n",
    "from pytorch3dunet.unet3d.buildingblocks import *\n",
    "from pytorch3dunet.unet3d.model import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u3d = UNet3D(in_channels = 1, out_channels = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainingset = dataset(file_path1=\"./reg_data/00/\",file_path2=\"./reg_data/04/\",force=0,start_index=144,end_index=720)\n",
    "trainingloader = DataLoader(dataset=Trainingset,batch_size=8,shuffle=True)\n",
    "\n",
    "Testingset = dataset(file_path1=\"./reg_data/00/\",file_path2=\"./reg_data/04/\",force=0,start_index=0,end_index=144)\n",
    "testloader = DataLoader(dataset=Testingset,batch_size=8,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_Unet(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    loss_total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets,_ in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs = inputs.unsqueeze(1).float()\n",
    "            targets = targets.unsqueeze(1).float()\n",
    "\n",
    "            generated_images = model(inputs)\n",
    "            loss = criterion(generated_images,targets)\n",
    "            loss_total += loss.item() * inputs.size(0)\n",
    "\n",
    "        loss_total /= len(val_loader.dataset)\n",
    "    return loss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Unet(model, train_loader, val_loader, num_epochs, device, lr=0.0002, beta1=0.5, beta2=0.999):\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "    # criterion = nn.L1Loss()\n",
    "    criterion = nn.MSELoss()\n",
    "    #criterion = nn.SmoothL1Loss()\n",
    "\n",
    "\n",
    "    model.to(device)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    min_val = 1.0\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_total = 0.0\n",
    "        model.train()\n",
    "        for inputs, targets,_ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs = inputs.unsqueeze(1).float()\n",
    "            targets = targets.unsqueeze(1).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            generated_images = model(inputs)\n",
    "\n",
    "            loss = criterion(generated_images,targets)\n",
    "            \n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_total += loss.item() * inputs.size(0)\n",
    "        loss_total /= len(train_loader.dataset)\n",
    "        train_losses.append(loss_total)\n",
    "\n",
    "        val_loss = eval_Unet(model,val_loader,criterion)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Training_Loss: {loss_total:.4f}, Val_Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < min_val:\n",
    "            min_val = val_loss\n",
    "            if val_loss < 0.07:\n",
    "                torch.save(model.state_dict(), f'./saved_model/old_unet/04_{epoch}_{val_loss:.4f}_lr1e-4.pth')\n",
    "    \n",
    "    torch.save(model.state_dict(), f'./saved_model/Unet/04_final_lr1e-4.pth')\n",
    "    print('Finished Training')\n",
    "\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_losses,  Val_losses = train_Unet(u3d, trainingloader,testloader, 400, device, lr=0.0001, beta1=0.5, beta2=0.999)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mt_xiangyu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
