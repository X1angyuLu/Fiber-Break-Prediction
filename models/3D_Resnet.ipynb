{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from dataloader import dataset\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_loss(z_a, z_b):\n",
    "    std_z_a = torch.sqrt(z_a.var(dim=0) + 1e-04)\n",
    "    std_z_b = torch.sqrt(z_b.var(dim=0) + 1e-04)\n",
    "    std_loss = torch.mean(F.relu(1 - std_z_a)) + torch.mean(F.relu(1 - std_z_b))\n",
    "    return std_loss\n",
    "\n",
    "\n",
    "def off_diagonal(x):\n",
    "    # return a flattened view of the off-diagonal elements of a square matrix\n",
    "    n, m = x.shape\n",
    "    assert n == m\n",
    "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "# covariance loss\n",
    "def cov_loss(z_a, z_b):\n",
    "    N = z_a.shape[0]\n",
    "    D = z_a.shape[1]\n",
    "    z_a = z_a - z_a.mean(dim=0)\n",
    "    z_b = z_b - z_b.mean(dim=0)\n",
    "    cov_z_a = (z_a.T @ z_a) / (N - 1)\n",
    "    cov_z_b = (z_b.T @ z_b) / (N - 1)\n",
    "    cov_loss = off_diagonal(cov_z_a).pow_(2).sum() / D + off_diagonal(cov_z_b).pow_(2).sum() / D\n",
    "    return cov_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm3d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet3D(nn.Module):\n",
    "    def __init__(self, block, layers, in_channels=1):\n",
    "        super(ResNet3D, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv3d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, 4096)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def ResNet18_3D(num_classes=1000, in_channels=3):\n",
    "    return ResNet3D(BasicBlock, [2, 2, 2, 2], in_channels=in_channels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ResNet18_3D(in_channels=1).to(device)\n",
    "input_tensor = torch.randn((2, 1, 64, 64, 64)).to(device)\n",
    "output = model(input_tensor)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainingset = dataset(file_path1=\"./reg_data/00/\",file_path2=\"./reg_data/12/\",force=0)\n",
    "trainingloader = DataLoader(dataset=Trainingset,batch_size=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for epoch in range(400):\n",
    "    loss_total = 0.0\n",
    "    mse_loss = 0.0\n",
    "    for inputs, targets, force in tqdm(trainingloader, desc=f\"Epoch {epoch+1}/{400}\"):\n",
    "\n",
    "        real_A = inputs.to(device).unsqueeze(1).float()\n",
    "        real_B = targets.to(device).unsqueeze(1).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        repr_a = model(real_A)\n",
    "        repr_b = model(real_B)\n",
    "\n",
    "        _sim_loss = criterion(repr_a, repr_b)\n",
    "        _std_loss = std_loss(repr_a, repr_b)\n",
    "        _cov_loss = cov_loss(repr_a, repr_b)\n",
    "\n",
    "        loss = 25 * _sim_loss + 25 * _std_loss + 1 * _cov_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_total += loss.item() * inputs.size(0)\n",
    "        mse_loss += _sim_loss.item() * inputs.size(0)\n",
    "\n",
    "    loss_total /= len(trainingloader.dataset)\n",
    "    mse_loss /= len(trainingloader.dataset)\n",
    "    losses.append(loss_total)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{400}], Loss: {loss_total:.4f}, mse: {mse_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses, label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Generator Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './saved_model/ResNet/model400.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = 0.0\n",
    "for inputs, targets,_ in trainingloader:\n",
    "    real_A = inputs.to(device).unsqueeze(1).float()\n",
    "    real_B = targets.to(device).unsqueeze(1).float()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    repr_a = model(real_A)\n",
    "    repr_b = model(real_B)\n",
    "    \n",
    "    loss = criterion(repr_a, repr_b)\n",
    "    \n",
    "    \n",
    "    mse += loss.item() * inputs.size(0)\n",
    "\n",
    "mse /= len(trainingloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mt_xiangyu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
